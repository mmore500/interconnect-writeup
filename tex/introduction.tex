\section{Introduction}

The challenge, and promise, of open-ended evolution has animated decades of inquiry and discussion within the artificial life community \citep{packard2019overview}.
The difficulty of devising models that reconstitute characteristic outcomes of open-ended evolution hints at profound philosophical and scientific blind spots in our understanding of the natural processes that gave rise to contemporary biology and ecology --- including ourselves.
Already, pursuit of open-ended evolution has yielded paradigm-shifting insights.
For example, novelty search, which demonstrated how processes promoting non-adaptive diversification can ultimately yield adaptive outcomes \citep{lehman2011abandoning}.
Such work lends insight to fundamental questions in evolutionary biology, such as the role --- or agnosticism -- of natural selection with respect to increases in complexity \citep{lehman2012evolution, lynch2007frailty} and the origins of evolvability \citep{lehman2013evolvability, kirschner1998evolvability}.
Evolution algorithms devised in support of open-ended evolution models and evolutionary artifacts generated by these models also promise to yield tangible broader impacts on society.
Possibilities include the generative design of consumer products, art, video games, and AI systems \citep{nguyen2015innovation, stanley2017open}.

Preceding decades have witnessed advances towards defining --- quantitatively and philosophically --- the concept of open-ended evolution \citep{lehman2012beyond, dolson2019modes, bedau1998classification}, as well as investigating causal phenomena that promote it such as ecological dynamics, selection, and evolvability, and evolvability \citep{dolson2019constructive, soros2014identifying, huizinga2018emergence}.
Together, methodological and theoretical advances have begun to yield evidence that the generative potential of artificial life systems is --- at least in part --- meaningfully constrained by available compute resources \citep{channon2019maximum}.

Since approximately the turn of the century, advances in the performance clock speed of traditional serial processing have tailed off.
At this point, existing technologies began to encounter fundamental constraints including power use and thermal dissipation \citep{sutter2005free}.
Injecting orders-of-magnitudes greater compute power into artifical life systems designed to study open-ended evolution will require taking advantage of modern parallel and distributed compute technologies.

In fact, digital evolution practitioners have a rich history of leveraging parallel and distributed hardware.
It is common practice to distribute multiple self-isolated instantiations of an evolutionary runs over multiple hardware units.
In scientific contexts, this practice yields replicate datasets that provide statistical power to answer a research question \citep{dolson2017spatial}.
In applied contexts, the
or,  to generate  the best solution from them (TODO cite).

It is also established practice to break isolation of populations evolving independently on distributed hardware by transplanting individuals between them.
Under this island model, however, selection operations are otherwise performed independently on each CPU.
Koza and collaborators' genetic programming work with a 1,000-cpu Beowulf cluster typifies this approach \citep{bennett1999building}.

In recent years, Sentient Technologies spearheaded digital evolution projects on an unprecedented computational scale, comprising over a million CPUs and capable of a peak performance of 9 petaflops \citep{miikkulainen2019evolving} .
According to its proponents, the scale and scalability of this DarkCycle system was a key aspect of its conceptualization \citep{gilbert_2015}.
Much of the assembled infrastructure was pieced together from heterogeneous providers and employed on a time-available basis \citep{blondeau2012distributed}.
It appears that, in some cases, this scheme involved the dynamic transfer of evaluation criteria between computational instances (in addition to individual genomes) \citep{hodjat2013distributed}.

Also notable from Sentient technologies was large-scale use of many massively-parallel hardware units (e.g., 100 GPUs) to evaluate the performance of candidate deep learning neural network architectures on image classification, language modeling, and image captioning problems.
Hardware parallelism accelerated the deep learning training process used to evaluate individual solutions \citep{miikkulainen2019evolving}.
Analogous work parallelizing the evaluation of an evolutionary individual over multiple test cases in the context of genetic programming using GPU hardware and vectorized CPU operations \citep{harding2007fast2, langdon2019continuous}.

% \citep{langdon2010large} breast cancer

With respect to incorporating parallel and distributed hardware in the context of open-ended evolution, we should likewise aim to distribute and concurrently evaluate computational elements constituting an evolutionary individual.
However --- unlike most existing applications of parallel and distributed computing to digital evolution --- we should also prioritize dynamic interactions between and within individuals.
Dynamic interaction between these concurrent components constituting an individual allows for generative developmental processes, understood as key to evolvability, and the production of emergent functionality among components.
Importantly, our approach to incorporating parallel and distributed hardware should also provide for dynamic interactions between contemporary evolving individuals.
Such interactions are understood as key to ecologies, co-evolution, and social interaction. %TODO

Dave Ackley has led towards such an distributed approach, laying out an ambitious vision for modular hardware at a theoretically unlimited scale \citep{ackley2011pursue} and demonstrating an algorithmic substrate for emergent agents that can take advantage of it \citep{ackley2018digital}.

%(TODO I've heard similar discussion made before somewhere, cite it)
While by no means a certainty, the idea is that orders-of-magnitude differences in compute power will open up qualitatively different possibilities with respect to open-ended evolution is also not entirely unfounded.
Analogy to spectacular advances achieved with artificial neural networks over the last decade illuminates a possible path towards this outcome.
As with digital evolution, artificial neural networks (ANNs) were traditionally understood as a highly-versatile but auxiliary methodology --- both techniques been described along the lines of "the second best way to do almost anything" \citep{miaoulis2008intelligent, eiben2015introduction}.
However, the utility and ubiquity of ANNs has since increased dramatically.
The development AlexNet is widely considered pivotal to this transformation.
AlexNet united methodological innovations from the field (such as big datasets, dropout, and ReLU) with GPU computing that enabled training of orders-of-magnitude-larger networks.
In fact, some aspects of aspects of their deep learning architecture were expressly modified to accommodate multi-GPU training \citep{krizhevsky2012imagenet}.
By adapting existing methodology to accommodate --- and take advantage of --- commercially available hardware AlexNet spurred the greater availability of compute resources to the research domain and eventually the introduction of custom hardware to expressly support deep learning \citep{jouppi2017datacenter}.

AlexNet set into motion within the field a cycle of repeatedly earning continued investment and developing methodology, software, and eventually hardware to take advantage of additional resources as well as continuing advances of on-silicon design and manufacturing.
In addition to developing hardware-agnostic theory and methodology, we believe that pushing the envelope of open-ended evolution will analogously require expressly designing systems to effectively leverage existing commercially-available parallel and distributed compute resources at circumstantially-feasible scales.
Modern high-performance scientific computing clusters appear perhaps the best target to start down this path.
These systems combine
\begin{itemize}
\item memory-sharing parallel architectures comprising dozens of cores (commonly targeted using OpenMP \citep{dagum1998openmp})
\item and low-latency high-throughput message-passing between distributed nodes (commonly targeted using MPI\citep{clarke1994mpi}).
\end{itemize}

In absolute terms such clusters lack in key characteristics highlighted for indefinite scalability: fault tolerance, arbitrary extensibility, and steady asynchronous operation.
However, at current scale --- and into the forseeable future --- they also offer opportunities not available in a indefinitely scalable framework: log-time interconnects.
TODO cite this, is this true?

Many natural systems --- such as ecosystems, genetic regulatory networks, and neural networks --- are known to exhibit small-world patterns of connectivity between components \citep{bassett2017small, fox2014herbivores, gaiteri2014beyond}.
In small-world graphs, mean path length (the number of edges traversed on a shortest-route) between arbitrary components scales logarithmically with system size \citep{watts1998collective}.
We anticipate that open-ended phenomena emerging across distributed hardware might also involve small-world connectivity dynamics.
As such a system scales, what implications might such connectivity have with respect to load on individual hardware components?
With respect to the latency and bandwidth of inter-component interactions as such a system scales?

In Section \ref{sec:results}, we analyze the scaling relationship between system size and expected node-to-node hops traversed between computational elements interacting as part of an emergent small-world network
\footnote{
TODO although relativistic come into play at much greater scales, node to node hops are relevant with current technologies at current scales
}
\begin{enumerate}
\item with and without hierarchical physical interconnects between computational nodes, and
\item with computational nodes embedded on one-, two-, or three-dimensional computational meshes.
\end{enumerate}

In Section \ref{sec:proof1}, we find that expected hops over edges weighted by edge betweenness centrality scales polynomially in all cases without hierarchical physical interconnects.
With hierarchical physical interconnects, a logarithmic scaling relationship can be achieved.

In Section \ref{sec:proof2} and \ref{sec:proof3} we find that hierarchical physical interconnects yield better best-case mean hops per edge in the one-dimensional case.
Interestingly, asymptotically better outcomes in two- and three- dimensions cannot be guaranteed by hierarchical physical interconnects.

In Section \ref{sec:proof4} we show that, with a specific traditional construction of small-world graphs, best-case mean hops per edge scales polynomially with graph size.
With hierarchical physical interconnects, a logarithmic scaling relationship can be achieved.

What could such a system, that facilitates system-managed interconnects (that under the hood  would rely on computationally-efficient hardware faculties) look like?
Finally, in Section \ref{sec:casestudy}, we turn to a case study to look at how an artificial life system might establish small-world interactions between computational elements distributed on different hardware nodes and take advantage of hierarchical physical interconnects.

We present an extension to upcoming work incorporating genetic programming with the DISHTINY platform for transitions in individuality \citep{moreno2019toward}.
This extension provides cells that are laid out on a grid with the capability --- through exploratory growth --- to establish explicit, direct interconnects with spatially distant cells.
We report a case study of where adaptive resource-sharing and messaging emerged over these interconnects.
Our preliminary implementation uses shared-memory thread-level parallelism.

DISHTINY is ... TODO
Although designed for scalability largely along the lines outlined by Ackley, our approach exchanges a uniform, evolutionary-passive substrate for manually-engineered self-replicators.
Evolutionary transitions in individuality provide a framework to unite self-replicators and induce meaningful functional synthesis of programmatic components tied to individual compute elements.
The system is designed to expose the underlying hardware reality (e.g., procedural expression of programs, hierarchical interconnects) so that the hardware capabilities can be fully taken advantage of.
As well as engineering-over complex features (interconnects, genetic transmission of information) along the lines of Channon

\begin{displayquote}
It is not computationally feasible (even if we knew how) for an OEE simulation to start from a sparse fog of hydrogen and helium and transition to a biological-level era, so it is clearly necessary to skip over or engineer in at least some complex features that arose through major transitions in our universe. \citep{channon2019maximum}
\end{displayquote}

become ascendant when different orders of magnitude of more compute power --- to the extent available by Ackley --- become available, and current work sets the stage for that eventuality. \citep{ackley2018alife}
This will address important questions in its own right about the computational (?) foundations of physical and biological reality.
